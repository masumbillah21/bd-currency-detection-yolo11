{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b24c93",
   "metadata": {},
   "source": [
    "### Dataset split summary (images/labels/missing/empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85d72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'split': 'train',\n",
       "  'images': 312,\n",
       "  'labels': 312,\n",
       "  'missing_labels': 0,\n",
       "  'extra_labels': 0,\n",
       "  'empty_label_files': 0,\n",
       "  'missing_label_names': [],\n",
       "  'extra_label_names': []},\n",
       " {'split': 'valid',\n",
       "  'images': 39,\n",
       "  'labels': 39,\n",
       "  'missing_labels': 0,\n",
       "  'extra_labels': 0,\n",
       "  'empty_label_files': 0,\n",
       "  'missing_label_names': [],\n",
       "  'extra_label_names': []},\n",
       " {'split': 'test',\n",
       "  'images': 39,\n",
       "  'labels': 39,\n",
       "  'missing_labels': 0,\n",
       "  'extra_labels': 0,\n",
       "  'empty_label_files': 0,\n",
       "  'missing_label_names': [],\n",
       "  'extra_label_names': []}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATASET_DIR = Path(\"dataset\")\n",
    "SPLITS = [\"train\", \"valid\", \"test\"]\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\"}\n",
    "\n",
    "def split_summary(split: str):\n",
    "    img_dir = DATASET_DIR / split / \"images\"\n",
    "    lbl_dir = DATASET_DIR / split / \"labels\"\n",
    "\n",
    "    imgs = [p for p in img_dir.iterdir() if p.is_file() and p.suffix.lower() in IMG_EXTS]\n",
    "    lbls = list(lbl_dir.glob(\"*.txt\"))\n",
    "\n",
    "    img_stems = {p.stem for p in imgs}\n",
    "    lbl_stems = {p.stem for p in lbls}\n",
    "\n",
    "    missing_labels = sorted(img_stems - lbl_stems)\n",
    "    extra_labels   = sorted(lbl_stems - img_stems)\n",
    "\n",
    "    empty_labels = []\n",
    "    for lp in lbls:\n",
    "        if lp.read_text(encoding=\"utf-8\", errors=\"ignore\").strip() == \"\":\n",
    "            empty_labels.append(lp.name)\n",
    "\n",
    "    return {\n",
    "        \"split\": split,\n",
    "        \"images\": len(imgs),\n",
    "        \"labels\": len(lbls),\n",
    "        \"missing_labels\": len(missing_labels),\n",
    "        \"extra_labels\": len(extra_labels),\n",
    "        \"empty_label_files\": len(empty_labels),\n",
    "        \"missing_label_names\": missing_labels[:10],\n",
    "        \"extra_label_names\": extra_labels[:10],\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for s in SPLITS:\n",
    "    if (DATASET_DIR / s).exists():\n",
    "        rows.append(split_summary(s))\n",
    "\n",
    "rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ffb9e",
   "metadata": {},
   "source": [
    "### Boxes per split + per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c2cc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'split': 'train',\n",
       "  'total_boxes': 436,\n",
       "  'boxes_per_class': [18, 48, 56, 13, 49, 9, 46, 36, 48, 44, 11, 31, 27],\n",
       "  'bad_lines_or_files': 0},\n",
       " {'split': 'valid',\n",
       "  'total_boxes': 60,\n",
       "  'boxes_per_class': [0, 9, 3, 0, 9, 2, 4, 4, 5, 8, 11, 3, 2],\n",
       "  'bad_lines_or_files': 0},\n",
       " {'split': 'test',\n",
       "  'total_boxes': 50,\n",
       "  'boxes_per_class': [0, 9, 2, 1, 10, 0, 4, 1, 6, 5, 1, 3, 8],\n",
       "  'bad_lines_or_files': 0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 13\n",
    "\n",
    "def count_boxes_in_split(split: str, num_classes: int):\n",
    "    lbl_dir = DATASET_DIR / split / \"labels\"\n",
    "    boxes_per_class = [0] * num_classes\n",
    "    total_boxes = 0\n",
    "    bad_files = 0\n",
    "\n",
    "    for lp in lbl_dir.glob(\"*.txt\"):\n",
    "        txt = lp.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "\n",
    "        for line in txt.splitlines():\n",
    "            parts = line.split()\n",
    "            if len(parts) != 5:\n",
    "                bad_files += 1\n",
    "                continue\n",
    "            try:\n",
    "                cls = int(float(parts[0]))\n",
    "            except:\n",
    "                bad_files += 1\n",
    "                continue\n",
    "\n",
    "            if 0 <= cls < num_classes:\n",
    "                boxes_per_class[cls] += 1\n",
    "                total_boxes += 1\n",
    "\n",
    "    return {\n",
    "        \"split\": split,\n",
    "        \"total_boxes\": total_boxes,\n",
    "        \"boxes_per_class\": boxes_per_class,\n",
    "        \"bad_lines_or_files\": bad_files\n",
    "    }\n",
    "\n",
    "box_stats = []\n",
    "for s in SPLITS:\n",
    "    if (DATASET_DIR / s).exists():\n",
    "        box_stats.append(count_boxes_in_split(s, NUM_CLASSES))\n",
    "\n",
    "box_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a78906",
   "metadata": {},
   "source": [
    "### Check same filenames exist in images + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0611d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: images=312 labels=312 missing_labels=0\n",
      "valid: images=39 labels=39 missing_labels=0\n",
      "test: images=39 labels=39 missing_labels=0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def check_split(split):\n",
    "    img_dir = Path(\"dataset\") / split / \"images\"\n",
    "    lbl_dir = Path(\"dataset\") / split / \"labels\"\n",
    "    imgs = {p.stem for p in img_dir.glob(\"*\")}\n",
    "    lbls = {p.stem for p in lbl_dir.glob(\"*.txt\")}\n",
    "    print(f\"{split}: images={len(imgs)} labels={len(lbls)} missing_labels={len(imgs - lbls)}\")\n",
    "\n",
    "for s in [\"train\", \"valid\", \"test\"]:\n",
    "    if (Path(\"dataset\") / s).exists():\n",
    "        check_split(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef2787",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
